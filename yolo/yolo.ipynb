{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly\n",
    "!pip install imgaug "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcsfuse images_heh ~/data/images\n",
    "!gcsfuse other_heh ~/data/other\n",
    "#!gcsfuse model_bucket ~/model/variables\n",
    "#!gcsfuse sn_test_bucket ~/sn_test_data\n",
    "#!gcsfuse sn_train_bucket ~/data/sn_images\n",
    "#!gcsfuse test_bucket ~/test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow as base library for neural networks\n",
    "import tensorflow as tf\n",
    "\n",
    "# keras as a layer on top of tensorflow\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# h5py is needed to store and load Keras models\n",
    "import h5py\n",
    " \n",
    "# matplotlib is needed to plot bounding boxes\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib inline\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import os, cv2, time, random\n",
    "import ntpath\n",
    "\n",
    "import utils\n",
    "\n",
    "import plotly.express as px\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import math\n",
    "import copy\n",
    "from utils import BoundBox, normalize, bbox_iou, decode_netout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_folder = Path(\"data\")\n",
    "image_folder = working_folder / \"images\"\n",
    "\n",
    "hamamatsu_rx_ids = list(range(0, 51))\n",
    "hamamatsu_360_ids = list(range(51, 101))\n",
    "aperio_ids = list(range(101, 151))\n",
    "leica_ids = list(range(151, 201))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_file = working_folder / \"other\" / \"MIDOG.json\"\n",
    "rows = []\n",
    "with open(annotation_file) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "    categories = {1: 'mitotic figure', 2: 'hard negative'}\n",
    "\n",
    "    for row in data[\"images\"]:\n",
    "        file_name = row[\"file_name\"]\n",
    "        image_id = row[\"id\"]\n",
    "        width = row[\"width\"]\n",
    "        height = row[\"height\"]\n",
    "\n",
    "        scanner  = \"Hamamatsu XR\"\n",
    "        if image_id in hamamatsu_360_ids:\n",
    "            scanner  = \"Hamamatsu S360\"\n",
    "        if image_id in aperio_ids:\n",
    "            scanner  = \"Aperio CS\"\n",
    "        if image_id in leica_ids:\n",
    "            scanner  = \"Leica GT450\"\n",
    "\n",
    "        for annotation in [anno for anno in data['annotations'] if anno[\"image_id\"] == image_id]:\n",
    "            box = annotation[\"bbox\"]\n",
    "            cat = categories[annotation[\"category_id\"]]\n",
    "\n",
    "            rows.append([file_name, image_id, width, height, box, cat, scanner])\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\"file_name\", \"image_id\", \"width\", \"height\", \"box\", \"cat\", \"scanner\"])\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['box_with_cat'] = df.apply(lambda row: [row['box'][0], row['box'][1], row['box'][2], row['box'][3], row['cat']], axis = 1)\n",
    "grouped_boxes_df = df[['image_id', 'box_with_cat']].groupby('image_id').box_with_cat.apply(list).reset_index()\n",
    "box_dict = grouped_boxes_df.set_index('image_id').T.to_dict('list')\n",
    "box_dict.get(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_slice_data(width, height, box, box_size, slice_size):\n",
    "    \n",
    "    (b_xmin, b_ymin, b_xmax, b_ymax) = box\n",
    "    \n",
    "    if b_xmin < 0: b_xmin = 0\n",
    "    if b_ymin < 0: b_ymin = 0\n",
    "    if b_xmax > width: b_xmax = width\n",
    "    if b_ymax > height: b_ymax = height\n",
    "    \n",
    "    xmin = random.randint(max(0, int(math.ceil(b_xmax) - slice_size)), min(int(b_xmin), width - slice_size)) \n",
    "    ymin = random.randint(max(0, int(math.ceil(b_ymax) - slice_size)), min(int(b_ymin), height - slice_size)) \n",
    "\n",
    "    return (xmin, ymin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boxes_for_slice(slice_xy, slice_size, image_boxes, box_size):\n",
    "    boxes = []\n",
    "    for box in image_boxes:\n",
    "        (b_xmin, b_ymin, _, _, cat) = box\n",
    "        if ((box[0] > slice_xy[0] - box_size/2 and box[0] < slice_xy[0] + slice_size - box_size/2) and\n",
    "            (box[1] > slice_xy[1] - box_size/2 and box[1] < slice_xy[1] + slice_size - box_size/2)):\n",
    "                boxes.append(box)\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "box_size = 50\n",
    "slice_size = 256\n",
    "\n",
    "df[\"slice\"] = df.apply(lambda row: get_random_slice_data(\n",
    "    row.width,\n",
    "    row.height,\n",
    "    row.box,\n",
    "    box_size,\n",
    "    slice_size\n",
    "), axis = 1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"slice_boxes\"] = df.apply(lambda row: get_boxes_for_slice(\n",
    "    row.slice,\n",
    "    slice_size,\n",
    "    box_dict.get(row.image_id)[0],\n",
    "    box_size,\n",
    "), axis = 1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_annotation(df, img_dir, train_dir, slice_size):\n",
    "    all_imgs = []\n",
    "    seen_labels = {}\n",
    "    \n",
    "    for i in range(1, 151):\n",
    "        if i in [30, 60, 90, 120]:\n",
    "            print(i, \"finished!\")\n",
    "        \n",
    "        temp_df = df[df['image_id'] == i]\n",
    "        #temp_name = 'output' + str(i) + '.tiff'\n",
    "        temp_name = temp_df.iloc[i][0]\n",
    "         \n",
    "        temp_image = cv2.imread(img_dir + temp_name)\n",
    "    \n",
    "        for index, row in temp_df.iterrows():\n",
    "\n",
    "            img = {'object':[]}\n",
    "\n",
    "            _, _, _, _, _, _, _, _, im_slice, slice_boxes = row\n",
    "\n",
    "            image = temp_image[im_slice[1]:im_slice[1]+slice_size, im_slice[0]:im_slice[0]+slice_size]\n",
    "            train_name = str(index) + '.tiff'\n",
    "            cv2.imwrite(train_dir + train_name, image)\n",
    "\n",
    "            img['file_name'] = train_dir + train_name\n",
    "            img['width'] = slice_size\n",
    "            img['height'] = slice_size\n",
    "\n",
    "            for box in slice_boxes:\n",
    "                (b_xmin, b_ymin, b_xmax, b_ymax, cat) = box\n",
    "                obj = {}\n",
    "                obj['name'] = cat\n",
    "                img['object'] += [obj]\n",
    "\n",
    "                obj['xmin'] = b_xmin - im_slice[0]\n",
    "                obj['ymin'] = b_ymin - im_slice[1]\n",
    "                obj['xmax'] = b_xmax - im_slice[0]\n",
    "                obj['ymax'] = b_ymax - im_slice[1]\n",
    "\n",
    "            if len(img['object']) > 0:\n",
    "                all_imgs += [img]\n",
    "        \n",
    "    return all_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = os.path.join('./', 'data', 'images/')\n",
    "train_path = os.path.join('./', 'data', 'train/')\n",
    "all_imgs = parse_annotation(df, image_path, train_path, slice_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['hard negative', 'mitotic figure']\n",
    "\n",
    "CLASS            = len(LABELS)\n",
    "CLASS_WEIGHTS    = np.ones(CLASS, dtype='float32')\n",
    "\n",
    "IMAGE_H, IMAGE_W = slice_size, slice_size\n",
    "GRID_H,  GRID_W  = 16 , 16\n",
    "BOX              = 5\n",
    "OBJ_THRESHOLD    = 0.3\n",
    "NMS_THRESHOLD    = 0.1\n",
    "ANCHORS          = [2.2, 2.2, 2.7, 2.7, 3.2, 3.2, 3.7, 3.7, 4.2, 4.2]\n",
    "\n",
    "NO_OBJECT_SCALE  = 1.0\n",
    "OBJECT_SCALE     = 5.0\n",
    "COORD_SCALE      = 1.0\n",
    "CLASS_SCALE      = 1.0\n",
    "\n",
    "BATCH_SIZE       = 32\n",
    "WARM_UP_BATCHES  = 100\n",
    "TRUE_BOX_BUFFER  = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_config = {\n",
    "    'IMAGE_H'         : IMAGE_H, \n",
    "    'IMAGE_W'         : IMAGE_W,\n",
    "    'GRID_H'          : GRID_H,  \n",
    "    'GRID_W'          : GRID_W,\n",
    "    'BOX'             : BOX,\n",
    "    'LABELS'          : LABELS,\n",
    "    'CLASS'           : len(LABELS),\n",
    "    'ANCHORS'         : ANCHORS,\n",
    "    'BATCH_SIZE'      : BATCH_SIZE,\n",
    "    'TRUE_BOX_BUFFER' : 50,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def space_to_depth_x2(x):\n",
    "    return tf.nn.space_to_depth(x, block_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def YOLO_network(input_img,true_bxs,CLASS):\n",
    "\n",
    "    # Layer 1\n",
    "    x = Conv2D(32, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False)(input_img)\n",
    "    x = BatchNormalization(name='norm_1')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Layer 2\n",
    "    x = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_2', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_2')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Layer 3\n",
    "    x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_3', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_3')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    # Layer 4\n",
    "    x = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_4', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_4')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    # Layer 5\n",
    "    x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_5', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_5')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    # Layer 6\n",
    "    x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_6')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    # Layer 7\n",
    "    x = Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_7', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_7')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    # Layer 8\n",
    "    x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_8', use_bias=False, input_shape=(512,512,3))(x)\n",
    "    x = BatchNormalization(name='norm_8')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    # Layer 9\n",
    "    x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_9', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_9')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    # Layer 10\n",
    "    x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_10', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_10')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    # Layer 11\n",
    "    x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_11', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_11')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    # Layer 12\n",
    "    x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_12', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_12')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    # Layer 13\n",
    "    x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_13', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_13')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    skip_connection = x\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Layer 14\n",
    "    x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_14', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_14')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    # Layer 15\n",
    "    x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_15', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_15')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    # Layer 16\n",
    "    x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_16', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_16')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    # Layer 17\n",
    "    x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_17', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_17')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    # Layer 18\n",
    "    x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_18', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_18')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    # Layer 19\n",
    "    x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_19', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_19')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    # Layer 20\n",
    "    x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_20', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_20')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    # Layer 21\n",
    "    skip_connection = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_21', use_bias=False)(skip_connection)\n",
    "    skip_connection = BatchNormalization(name='norm_21')(skip_connection)\n",
    "    skip_connection = LeakyReLU(alpha=0.1)(skip_connection)\n",
    "    skip_connection = Lambda(space_to_depth_x2)(skip_connection)\n",
    "\n",
    "    x = concatenate([skip_connection, x])\n",
    "\n",
    "    # Layer 22\n",
    "    x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_22', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_22')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    # Layer 23\n",
    "    x = Conv2D(BOX * (4 + 1 + CLASS), (1,1), strides=(1,1), padding='same', name='conv_23')(x)\n",
    "    output = Reshape((GRID_H, GRID_W, BOX, 4 + 1 + CLASS))(x)\n",
    "    output = Lambda(lambda args: args[0])([output, true_bxs])\n",
    "\n",
    "    model = Model([input_img, true_bxs], output)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
    "true_boxes  = Input(shape=(1, 1, 1, TRUE_BOX_BUFFER , 4))\n",
    "\n",
    "model = YOLO_network(input_image, true_boxes, CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bounding_box(image, model, obj_threshold, nms_threshold, anchors, nb_class):\n",
    "    \"\"\"\n",
    "        Predict bounding boxes for a given image.\n",
    "    \"\"\"    \n",
    "    input_image = image / 255. # rescale intensity to [0, 1]\n",
    "    input_image = input_image[:,:,::-1]\n",
    "    img_shape = image.shape\n",
    "    input_image = np.expand_dims(input_image, 0) \n",
    "\n",
    "    # define variable needed to process input image\n",
    "    dummy_array = np.zeros((1,1,1,1,TRUE_BOX_BUFFER,4))\n",
    "\n",
    "    # get output from network\n",
    "    netout = model.predict([input_image, dummy_array])\n",
    "    \n",
    "    return utils.decode_netout(netout[0], obj_threshold, nms_threshold, anchors, nb_class)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from loss_utils import *\n",
    "\n",
    "class Loss(tf.keras.losses.Loss):\n",
    "\n",
    "    EPSILON = 1e-6\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        batch_size,\n",
    "        grid_width,\n",
    "        grid_height,\n",
    "        anchors,\n",
    "        n_boxes=1000,\n",
    "        scales=Scales()\n",
    "    ):\n",
    "\n",
    "        self._batch_size = batch_size\n",
    "        self._grid_width = grid_width\n",
    "        self._grid_height = grid_height\n",
    "\n",
    "        self._n_boxes = n_boxes\n",
    "        self._anchors = anchors\n",
    "        self._scales = scales\n",
    "\n",
    "        self._grid = get_cell_grid(\n",
    "            self._batch_size, self._n_boxes, self._grid_width, self._grid_height\n",
    "        )\n",
    "        \n",
    "        self.reduction = tf.keras.losses.Reduction.AUTO\n",
    "        self.name = 'loss'\n",
    "\n",
    "    def __call__(self, y_true, y_pred, sample_weight=None):\n",
    "\n",
    "        # prediction\n",
    "        pred_box_xy = tf.sigmoid(y_pred[..., :2]) + self._grid\n",
    "        pred_box_wh = tf.exp(y_pred[..., 2:4]) * np.reshape(\n",
    "            self._anchors, [1, 1, 1, self._n_boxes, 2]\n",
    "        )\n",
    "        pred_box_conf = tf.sigmoid(y_pred[..., 4])\n",
    "        pred_box_class = y_pred[..., 5:]\n",
    "\n",
    "        # ground thuth\n",
    "        true_box_xy = y_true[..., :2]\n",
    "        true_box_wh = y_true[..., 2:4]\n",
    "        true_box_conf = (\n",
    "            tf_iou(true_box_xy, true_box_wh, pred_box_xy, pred_box_wh) * y_true[..., 4]\n",
    "        )\n",
    "        true_box_class = tf.argmax(y_true[..., 5:], -1)\n",
    "\n",
    "        # masks\n",
    "        # TODO calculate responsible anchorbox (not neccesary when one anchor box)\n",
    "\n",
    "        # expand for  2 values (x,y) and (w,h) for coord scale\n",
    "        coord_mask = tf.expand_dims(y_true[..., 4], axis=-1) * self._scales.coord_scale\n",
    "        conf_mask = (y_true[..., 4] + self._scales.no_object_scale) * self._scales.object_scale\n",
    "        class_mask = y_true[..., 4] * self._scales.class_scale\n",
    "\n",
    "        # normalization factor\n",
    "        nb_coord_norm = tf.reduce_sum(tf.cast(coord_mask > 0.0, dtype=tf.float32)) + Loss.EPSILON\n",
    "        nb_conf_norm = tf.reduce_sum(tf.cast(conf_mask > 0.0, dtype=tf.float32)) + Loss.EPSILON\n",
    "        nb_class_norm = tf.reduce_sum(tf.cast(class_mask > 0.0, dtype=tf.float32)) + Loss.EPSILON\n",
    "\n",
    "        # losses\n",
    "        loss_xy = (\n",
    "            tf.reduce_sum(tf.square(true_box_xy - pred_box_xy) * coord_mask)\n",
    "            / nb_coord_norm\n",
    "            / 2.0\n",
    "        )\n",
    "        loss_wh = (\n",
    "            tf.reduce_sum(tf.square(true_box_wh - pred_box_wh) * coord_mask)\n",
    "            / nb_coord_norm\n",
    "            / 2.0\n",
    "        )\n",
    "        loss_conf = (\n",
    "            tf.reduce_sum(tf.square(true_box_conf - pred_box_conf) * conf_mask)\n",
    "            / nb_conf_norm\n",
    "            / 2.0\n",
    "        )\n",
    "        loss_class = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            labels=true_box_class, logits=pred_box_class\n",
    "        )\n",
    "        loss_class = tf.reduce_sum(loss_class * class_mask) / nb_class_norm\n",
    "\n",
    "        # combine all terms\n",
    "        loss = loss_xy + loss_wh + loss_conf + loss_class\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', \n",
    "                           min_delta=0.001, \n",
    "                           patience=10, \n",
    "                           mode='min', \n",
    "                           verbose=1)\n",
    "\n",
    "checkpoint = ModelCheckpoint('best_model.h5',\n",
    "                             monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='min', \n",
    "                             period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator(Sequence):\n",
    "    def __init__(self, images,\n",
    "                       config,\n",
    "                       shuffle=True,\n",
    "                       jitter=True,\n",
    "                       norm=None):\n",
    "        self.generator = None\n",
    "\n",
    "        self.images = images\n",
    "        self.config = config\n",
    "\n",
    "        self.shuffle = shuffle\n",
    "        self.jitter  = jitter\n",
    "        self.norm    = norm\n",
    "\n",
    "        self.counter = 0\n",
    "        self.anchors = [BoundBox(0, 0, config['ANCHORS'][2*i], config['ANCHORS'][2*i+1]) for i in range(int(len(config['ANCHORS'])//2))]\n",
    "\n",
    "        ### augmentors by https://github.com/aleju/imgaug\n",
    "        sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "\n",
    "        # Define our sequence of augmentation steps that will be applied to every image\n",
    "        self.aug_pipe = iaa.Sequential(\n",
    "            [\n",
    "                iaa.SomeOf((0, 5),\n",
    "                    [\n",
    "                        iaa.OneOf([\n",
    "                            iaa.GaussianBlur((0, 3.0)), # blur images with a sigma between 0 and 3.0\n",
    "                            iaa.AverageBlur(k=(2, 7)), # blur image using local means with kernel sizes between 2 and 7\n",
    "                            iaa.MedianBlur(k=(3, 11)), # blur image using local medians with kernel sizes between 2 and 7\n",
    "                        ]),\n",
    "                        iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)), # sharpen images\n",
    "                        iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5), # add gaussian noise to images\n",
    "                        iaa.OneOf([\n",
    "                            iaa.Dropout((0.01, 0.1), per_channel=0.5), # randomly remove up to 10% of the pixels\n",
    "                        ]),\n",
    "                        iaa.Add((-10, 10), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\n",
    "                        iaa.Multiply((0.5, 1.5), per_channel=0.5), # change brightness of images (50-150% of original value)\n",
    "                        iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5), # improve or worsen the contrast\n",
    "                    ],\n",
    "                    random_order=True\n",
    "                )\n",
    "            ],\n",
    "            random_order=True\n",
    "        )\n",
    "\n",
    "        if shuffle: np.random.shuffle(self.images)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(float(len(self.images))/self.config['BATCH_SIZE']))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        l_bound = idx*self.config['BATCH_SIZE']\n",
    "        r_bound = (idx+1)*self.config['BATCH_SIZE']\n",
    "\n",
    "        if r_bound > len(self.images):\n",
    "            r_bound = len(self.images)\n",
    "            l_bound = r_bound - self.config['BATCH_SIZE']\n",
    "\n",
    "        instance_count = 0\n",
    "\n",
    "        x_batch = np.zeros((r_bound - l_bound, self.config['IMAGE_H'], self.config['IMAGE_W'], 3))\n",
    "        b_batch = np.zeros((r_bound - l_bound, 1     , 1     , 1    ,  self.config['TRUE_BOX_BUFFER'], 4))\n",
    "        y_batch = np.zeros((r_bound - l_bound, self.config['GRID_H'],  self.config['GRID_W'], self.config['BOX'], 4+1+self.config['CLASS']))\n",
    "\n",
    "        for train_instance in self.images[l_bound:r_bound]:\n",
    "            # augment input image and fix object's position and size\n",
    "            img, all_objs = self.aug_image(train_instance, jitter=self.jitter)\n",
    "\n",
    "            # construct output from object's x, y, w, h\n",
    "            true_box_index = 0\n",
    "\n",
    "            for obj in all_objs:\n",
    "                if obj['xmax'] > obj['xmin'] and obj['ymax'] > obj['ymin'] and obj['name'] in self.config['LABELS']:\n",
    "                    center_x = .5*(obj['xmin'] + obj['xmax'])\n",
    "                    center_x = center_x / (float(self.config['IMAGE_W']) / self.config['GRID_W'])\n",
    "                    center_y = .5*(obj['ymin'] + obj['ymax'])\n",
    "                    center_y = center_y / (float(self.config['IMAGE_H']) / self.config['GRID_H'])\n",
    "\n",
    "                    grid_x = int(np.floor(center_x))\n",
    "                    grid_y = int(np.floor(center_y))\n",
    "\n",
    "                    if grid_x < self.config['GRID_W'] and grid_y < self.config['GRID_H']:\n",
    "                        obj_indx  = self.config['LABELS'].index(obj['name'])\n",
    "\n",
    "                        center_w = (obj['xmax'] - obj['xmin']) / (float(self.config['IMAGE_W']) / self.config['GRID_W']) # unit: grid cell\n",
    "                        center_h = (obj['ymax'] - obj['ymin']) / (float(self.config['IMAGE_H']) / self.config['GRID_H']) # unit: grid cell\n",
    "\n",
    "                        box = [center_x, center_y, center_w, center_h]\n",
    "\n",
    "                        # find the anchor that best predicts this box\n",
    "                        best_anchor = -1\n",
    "                        max_iou     = -1\n",
    "\n",
    "                        shifted_box = BoundBox(0,\n",
    "                                               0,\n",
    "                                               center_w,\n",
    "                                               center_h)\n",
    "\n",
    "                        for i in range(len(self.anchors)):\n",
    "                            anchor = self.anchors[i]\n",
    "                            iou    = bbox_iou(shifted_box, anchor)\n",
    "\n",
    "                            if max_iou < iou:\n",
    "                                best_anchor = i\n",
    "                                max_iou     = iou\n",
    "\n",
    "                        # assign ground truth x, y, w, h, confidence and class probs to y_batch\n",
    "                        y_batch[instance_count, grid_y, grid_x, best_anchor, 0:4] = box\n",
    "                        y_batch[instance_count, grid_y, grid_x, best_anchor, 4  ] = 1.\n",
    "                        y_batch[instance_count, grid_y, grid_x, best_anchor, 5+obj_indx] = 1\n",
    "\n",
    "                        # assign the true box to b_batch\n",
    "                        b_batch[instance_count, 0, 0, 0, true_box_index] = box\n",
    "\n",
    "                        true_box_index += 1\n",
    "                        true_box_index = true_box_index % self.config['TRUE_BOX_BUFFER']\n",
    "\n",
    "            # assign input image to x_batch\n",
    "            if self.norm != None:\n",
    "                x_batch[instance_count] = self.norm(img)\n",
    "            else:\n",
    "                # plot image and bounding boxes for sanity check\n",
    "                for obj in all_objs:\n",
    "                    if obj['xmax'] > obj['xmin'] and obj['ymax'] > obj['ymin']:\n",
    "                        cv2.rectangle(img[:,:,::-1], (obj['xmin'],obj['ymin']), (obj['xmax'],obj['ymax']), (255,0,0), 3)\n",
    "                        cv2.putText(img[:,:,::-1], obj['name'],\n",
    "                                    (obj['xmin']+2, obj['ymin']+12),\n",
    "                                    0, 1.2e-3 * img.shape[0],\n",
    "                                    (0,255,0), 2)\n",
    "\n",
    "                x_batch[instance_count] = img\n",
    "\n",
    "            # increase instance counter in current batch\n",
    "            instance_count += 1\n",
    "\n",
    "        self.counter += 1\n",
    "\n",
    "        return [x_batch, b_batch], y_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle: np.random.shuffle(self.images)\n",
    "        self.counter = 0\n",
    "\n",
    "    def aug_image(self, train_instance, jitter):\n",
    "        image_name = train_instance['file_name']\n",
    "        image = cv2.imread(image_name)\n",
    "        \n",
    "        h, w, c = image.shape\n",
    "\n",
    "        all_objs = copy.deepcopy(train_instance['object'])\n",
    "\n",
    "        if jitter:\n",
    "            ### scale the image\n",
    "            scale = np.random.uniform() / 10. + 1.\n",
    "            image = cv2.resize(image, (0,0), fx = scale, fy = scale)\n",
    "\n",
    "            ### translate the image\n",
    "            max_offx = (scale-1.) * w\n",
    "            max_offy = (scale-1.) * h\n",
    "            offx = int(np.random.uniform() * max_offx)\n",
    "            offy = int(np.random.uniform() * max_offy)\n",
    "\n",
    "            image = image[offy : (offy + h), offx : (offx + w)]\n",
    "\n",
    "            ### flip the image\n",
    "            flip = np.random.binomial(1, .5)\n",
    "            if flip > 0.5: image = cv2.flip(image, 1)\n",
    "\n",
    "            #image = self.aug_pipe.augment_image(image)\n",
    "\n",
    "        # resize the image to standard size\n",
    "        image = cv2.resize(image, (self.config['IMAGE_H'], self.config['IMAGE_W']))\n",
    "        image = image[:,:,::-1]\n",
    "\n",
    "        # fix object's position and size\n",
    "        for obj in all_objs:\n",
    "            for attr in ['xmin', 'xmax']:\n",
    "                if jitter: obj[attr] = int(obj[attr] * scale - offx)\n",
    "\n",
    "                obj[attr] = int(obj[attr] * float(self.config['IMAGE_W']) / w)\n",
    "                obj[attr] = max(min(obj[attr], self.config['IMAGE_W']), 0)\n",
    "\n",
    "            for attr in ['ymin', 'ymax']:\n",
    "                if jitter: obj[attr] = int(obj[attr] * scale - offy)\n",
    "\n",
    "                obj[attr] = int(obj[attr] * float(self.config['IMAGE_H']) / h)\n",
    "                obj[attr] = max(min(obj[attr], self.config['IMAGE_H']), 0)\n",
    "\n",
    "            if jitter and flip > 0.5:\n",
    "                xmin = obj['xmin']\n",
    "                obj['xmin'] = self.config['IMAGE_W'] - obj['xmax']\n",
    "                obj['xmax'] = self.config['IMAGE_W'] - xmin\n",
    "\n",
    "        return image, all_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_percentage = 0.95\n",
    "train_valid_split = int(training_data_percentage * len(all_imgs))\n",
    "\n",
    "train_batch = BatchGenerator(all_imgs[:train_valid_split], generator_config, norm=utils.normalize)\n",
    "valid_batch = BatchGenerator(all_imgs[train_valid_split:], generator_config, norm=utils.normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "link = 'https://surfdrive.surf.nl/files/index.php/s/HGmdukdYpnyt2NV/download'\n",
    "file_name = \"pretrained_yolo_weights.zip\"\n",
    "with open(file_name, \"wb\") as f:\n",
    "        response = requests.get(link, stream=True)\n",
    "        total_length = response.headers.get('content-length')\n",
    "        if total_length is None: # no content length header\n",
    "            f.write(response.content)\n",
    "        else:\n",
    "            dl = 0\n",
    "            total_length = int(total_length)\n",
    "            for data in tqdm(response.iter_content(chunk_size=4096), desc='Downloading data'):\n",
    "                dl += len(data)\n",
    "                f.write(data)\n",
    "with zipfile.ZipFile(file_name,\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"./\")\n",
    "os.remove('./pretrained_yolo_weights.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to file of Pascal VOC YOLO weights\n",
    "wt_path = os.path.join(os.getcwd(), './pretrained_yolo_weights.h5')\n",
    "model.load_weights(wt_path)\n",
    "print(\"Weights loaded from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# path to best model\n",
    "#from tensorflow import keras\n",
    "#model = keras.models.load_model('model')\n",
    "#print(\"Weights loaded from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of epochs\n",
    "n_epoch = 10\n",
    "learning_rate = 1e-5\n",
    "\n",
    "# Define Adam optimizer\n",
    "optimizer = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.99, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "# compile YOLO model\n",
    "loss = Loss(BATCH_SIZE, GRID_H, GRID_W, ANCHORS, n_boxes = 5)\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "# do training\n",
    "history = model.fit(train_batch,\n",
    "            validation_data = valid_batch,\n",
    "            epochs=n_epoch,\n",
    "            callbacks=[early_stop, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('best_model_da.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_image(image, slice_size):\n",
    "    slices = []\n",
    "    \n",
    "    h, w, _ = image.shape\n",
    "    slices_y = math.ceil(h / slice_size)\n",
    "    slices_x = math.ceil(w / slice_size)\n",
    "    \n",
    "    for y in range(slices_y):\n",
    "        for x in range(slices_x):\n",
    "\n",
    "            x_min = x * slice_size\n",
    "            y_min = y * slice_size\n",
    "\n",
    "            if x_min + slice_size > w: x_min = w - slice_size\n",
    "            if y_min + slice_size > h: y_min = h - slice_size\n",
    "\n",
    "            slices.append((x_min, y_min))\n",
    "    \n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = os.path.join('./', 'data', 'images/')\n",
    "#num_list = range(1, 151)\n",
    "num_list = random.sample(range(1, 151), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = []\n",
    "thresholds = np.arange(0.075, 0.4, 0.003)\n",
    "slice_size = 256\n",
    "\n",
    "for im_n in num_list:\n",
    "\n",
    "    w = 2000\n",
    "    h = 2000\n",
    "    image = cv2.imread(image_path + str(im_n).zfill(3) + '.tiff')\n",
    "    #image = image[0:h, 0:w]\n",
    "    \n",
    "    true_data = df.loc[df['image_id'] == im_n]['box'].tolist()\n",
    "    boxes = []\n",
    "    \n",
    "    obj_threshold=thresholds[0]\n",
    "    slices = slice_image(image, slice_size)\n",
    "    h, w, _ = image.shape\n",
    "\n",
    "    for slice_xy in slices:\n",
    "        image_slice = image[slice_xy[1]:slice_xy[1]+slice_size, slice_xy[0]:slice_xy[0]+slice_size]\n",
    "        slice_boxes = predict_bounding_box(image_slice, model, obj_threshold, NMS_THRESHOLD, ANCHORS, CLASS)\n",
    "        slice_boxes = [box for box in slice_boxes if box.label == 1]\n",
    "        for slice_box in slice_boxes:\n",
    "            slice_box.x = slice_size / w * slice_box.x + slice_xy[0] / w\n",
    "            slice_box.y = slice_size / h * slice_box.y + slice_xy[1] / h\n",
    "        boxes = boxes + slice_boxes\n",
    "\n",
    "    for box in boxes:\n",
    "        box.x = w * box.x\n",
    "        box.y = h * box.y\n",
    "\n",
    "    to_remove = []\n",
    "    for i, box_1 in enumerate(boxes):\n",
    "        for box_2 in boxes:\n",
    "            if ((box_1.x < box_2.x + box_size*1.5 and box_1.x > box_2.x - box_size*1.5) and\n",
    "                (box_1.y < box_2.y + box_size*1.5 and box_1.y > box_2.y - box_size*1.5) and\n",
    "                box_1.score < box_2.score):\n",
    "                    to_remove.append(i)\n",
    "\n",
    "    for index in sorted(set(to_remove), reverse=True):\n",
    "        del boxes[index]\n",
    "    \n",
    "    f1 = []\n",
    "    for obj_threshold in thresholds:\n",
    "\n",
    "        slice_boxes = [box for box in boxes if box.score > obj_threshold]\n",
    "        positives = []\n",
    "        for i, box_1 in enumerate(slice_boxes):\n",
    "            for j, box_2 in enumerate(true_data):\n",
    "                if ((box_1.x < box_2[0] + 3/2 * box_size and box_1.x > box_2[0] - 0.5 * box_size) and\n",
    "                    (box_1.y < box_2[1] + 3/2 * box_size and box_1.y > box_2[1] - 0.5 * box_size)):\n",
    "                        positives.append(i)\n",
    "        total = len(slice_boxes)\n",
    "        if total == 0: total = -1\n",
    "        precision = len(set(positives)) / total\n",
    "        recall = len(set(positives)) / 6\n",
    "        if (precision + recall) == 0 : precision = -1\n",
    "        f1.append(2 * (precision * recall) / (precision + recall))\n",
    "    \n",
    "    f1_scores.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_f1 = np.mean(f1_scores, axis=0)\n",
    "best_threshold = thresholds[np.where(avg_f1 == np.amax(avg_f1))[0][0]]\n",
    "best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox2csv(image_n, boxes, csv_file):\n",
    "    \n",
    "    csv_out = open(csv_file, 'a')\n",
    "    \n",
    "    slide = str(image_n).zfill(2)\n",
    "    \n",
    "    for box in boxes:\n",
    "        \n",
    "        line = slide + ',' + str(round(box.x)) + ',' + str(round(box.y))\n",
    "        csv_out.write(line + '\\n')\n",
    "\n",
    "    csv_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = './outputs'\n",
    "#test_dir = os.path.join('./','sn_test_data/')\n",
    "test_dir = os.path.join('./','test_data/')\n",
    "file_name = 'output'\n",
    "\n",
    "slice_size = 256\n",
    "obj_threshold=best_threshold\n",
    "\n",
    "header = 'slide, x, y\\n'\n",
    "csv_file = os.path.join(out_dir,'test_set.csv')\n",
    "\n",
    "with open(csv_file, 'w') as csv_out:\n",
    "    csv_out.write(header)\n",
    "\n",
    "for image_n in range(1, 35):\n",
    "    \n",
    "    boxes = []\n",
    "    #image_name = file_name + str(image_n) + '.tiff'\n",
    "    image_name = str(image_n).zfill(2) + '.tif' \n",
    "    image = cv2.imread(test_dir + image_name)\n",
    "    slices = slice_image(image, slice_size)\n",
    "    h, w, _ = image.shape\n",
    "\n",
    "    for slice_xy in slices:\n",
    "        image_slice = image[slice_xy[1]:slice_xy[1]+slice_size, slice_xy[0]:slice_xy[0]+slice_size]\n",
    "        slice_boxes = predict_bounding_box(image_slice, model, obj_threshold, NMS_THRESHOLD, ANCHORS, CLASS)\n",
    "        slice_boxes = [box for box in slice_boxes if box.label == 1]\n",
    "        for slice_box in slice_boxes:\n",
    "            slice_box.x = slice_size / w * slice_box.x + slice_xy[0] / w\n",
    "            slice_box.y = slice_size / h * slice_box.y + slice_xy[1] / h\n",
    "        boxes = boxes + slice_boxes\n",
    "    \n",
    "    for box in boxes:\n",
    "        box.x = w * box.x\n",
    "        box.y = h * box.y\n",
    "    \n",
    "    to_remove = []\n",
    "    for i, box_1 in enumerate(boxes):\n",
    "        for box_2 in boxes:\n",
    "            if ((box_1.x < box_2.x + box_size*1.5 and box_1.x > box_2.x - box_size*1.5) and\n",
    "                (box_1.y < box_2.y + box_size*1.5 and box_1.y > box_2.y - box_size*1.5) and\n",
    "                box_1.score < box_2.score):\n",
    "                    to_remove.append(i)\n",
    "\n",
    "    for index in sorted(set(to_remove), reverse=True):\n",
    "        del boxes[index]\n",
    "        \n",
    "    bbox2csv(image_n, boxes, csv_file)\n",
    "    print(image_n, 'finished!')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
